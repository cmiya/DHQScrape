{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHQ Author Scrape:\n",
    "- Iterate through each volume/article of DHQ\n",
    "- Write year, vol., num., title and authors to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "\n",
    "r  = requests.get(\"http://www.digitalhumanities.org/dhq/\")\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "#print(soup.prettify())\n",
    "\n",
    "nav = soup.find(\"div\", {\"id\": \"leftsidenav\"})\n",
    "index = nav.find_all('a')\n",
    "\n",
    "#Extract URL of each Issue\n",
    "for issues in index:\n",
    "    issue = issues.get('href')\n",
    "    r2  = requests.get(\"http://www.digitalhumanities.org\" + issue)\n",
    "    soup = BeautifulSoup(r2.content, \"lxml\")\n",
    "    \n",
    "    #Extract URL of each Article\n",
    "    for article in soup.find_all(\"div\", {\"class\": \"articleInfo\"}):\n",
    "        link = article.find('a')\n",
    "        article2 = link.get('href')\n",
    "        #print(article2)\n",
    "\n",
    "        #Get Article\n",
    "        r2  = requests.get(\"http://www.digitalhumanities.org\" + article2)\n",
    "        soup = BeautifulSoup(r2.content, \"lxml\")\n",
    "\n",
    "        #Get Title\n",
    "        title = soup.title.get_text()\n",
    "        newtitle = title.strip()\n",
    "        replaced = re.sub('\\s{2,}', ' ', newtitle)\n",
    "        t = re.search('y:\\s(.*)', replaced)\n",
    "        title2 = t.group(1)\n",
    "        #print(title2)\n",
    "\n",
    "        #Get Year, Volume, Number\n",
    "        v = re.search('vol\\/(\\d+)', article2)\n",
    "        vol = v.group(1)\n",
    "        #print(vol)\n",
    "        n = re.search('vol\\/\\d+\\/(\\d+)', article2)\n",
    "        num = n.group(1)\n",
    "        #print(num)\n",
    "        year = int(vol) + 2006\n",
    "        #print(year)\n",
    "\n",
    "        #Get Author Names\n",
    "        a_list = []\n",
    "        for names in soup.find_all(\"div\", {\"class\": \"author\"}):\n",
    "            name = names.find('a').get_text()\n",
    "            name = name.strip()\n",
    "            name = re.sub('\\s{2,}', ' ', name)\n",
    "            a_list.append(name)\n",
    "        a_list = ','.join(a_list)\n",
    "        #print(a_list)\n",
    "        #len(a_list)\n",
    "\n",
    "        final = {\n",
    "            \"title\" : title2,\n",
    "            \"year\" : year,\n",
    "            \"volume\" : vol,\n",
    "            \"number\" : num,\n",
    "            \"authors\" : a_list,\n",
    "            }\n",
    "        print(final)\n",
    "        \n",
    "        #Write to .csv file\n",
    "        import csv\n",
    "        with open('DHQ.csv', 'a') as csvfile:\n",
    "            fieldnames = ['year', 'volume', 'number', 'title', 'authors']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            #writer.writeheader()\n",
    "            writer.writerow({\n",
    "            \"title\" : title2,\n",
    "            \"year\" : year,\n",
    "            \"volume\" : vol,\n",
    "            \"number\" : num,\n",
    "            \"authors\" : a_list,})\n",
    "            time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
